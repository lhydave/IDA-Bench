{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f971d84",
   "metadata": {},
   "source": [
    "# LLMInteractor Examples\n",
    "\n",
    "This notebook demonstrates example usage of LLMInteractor with and without code execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8df47676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llm_interact import LLMConfig, LLMInteractor\n",
    "from logger import configure_global_logger\n",
    "import logging\n",
    "configure_global_logger(logging.INFO, \"./examples.log\")\n",
    "\n",
    "# Create checkpoints directory if it doesn't exist\n",
    "os.makedirs(\"./checkpoints\", exist_ok=True)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7f541c",
   "metadata": {},
   "source": [
    "## Example 1: LLMInteractor without code execution\n",
    "\n",
    "This example uses litellm to call API directly without executing code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e77ff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_without_code_execution():\n",
    "    \"\"\"\n",
    "    Example of using LLMInteractor without code execution.\n",
    "    Uses litellm to call API directly.\n",
    "    \"\"\"\n",
    "    print(\"=== Example: LLMInteractor without code execution ===\")\n",
    "\n",
    "    # Load configuration from TOML file\n",
    "    config = LLMConfig.from_toml(\"./llm_config.toml\")\n",
    "\n",
    "    # Make sure code execution is disabled for this example\n",
    "    config.run_code = False\n",
    "    config.checkpoint_path = \"./checkpoints/no_code_example.json\"\n",
    "\n",
    "    # Initialize the interactor\n",
    "    interactor = LLMInteractor(config)\n",
    "\n",
    "    # Send messages to the LLM\n",
    "    messages = [\n",
    "        \"Hello! Can you briefly explain what quantum computing is?\",\n",
    "        \"Can you give me a simple example of a quantum algorithm?\",\n",
    "        \"How does that differ from classical computing?\",\n",
    "    ]\n",
    "\n",
    "    responses = interactor.send_all(messages)\n",
    "\n",
    "    print(\"responses are actually the same as interactor.messages\")\n",
    "    print(\"responses == interactor.messages: \", responses == interactor.messages)\n",
    "    # Print the conversation\n",
    "    print(\"\\nConversation history:\")\n",
    "    for i, msg in enumerate(interactor.messages):\n",
    "        role = msg[\"role\"]\n",
    "        content = msg[\"content\"]\n",
    "        print(f\"\\n[{role.upper()}]:\\n{content[:100]}...\")  # Show first 100 chars\n",
    "\n",
    "    # Save checkpoint (this happens automatically during send_all, but can be called manually)\n",
    "    interactor.store_checkpoint()\n",
    "    print(f\"\\nCheckpoint saved to {config.checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "576aec1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Example: LLMInteractor without code execution ===\n",
      "2025-04-27 20:10:16 - DataSciBench - INFO - Loaded configuration from ./llm_config.toml\n",
      "2025-04-27 20:10:16 - DataSciBench - INFO - Initialized LLMInteractor with model: gemini/gemini-2.0-flash-lite, temperature: 0.4\n",
      "2025-04-27 20:10:16 - DataSciBench - INFO - Sending 3 messages to LLM\n",
      "2025-04-27 20:10:16 - DataSciBench - INFO - Checkpoint saved to ./checkpoints/no_code_example.json\n",
      "2025-04-27 20:10:16 - DataSciBench - INFO - Calling LLM API with a message (total length: ~57 chars)\n",
      "2025-04-27 20:10:17 - DataSciBench - INFO - LLM API call successful on attempt 1\n",
      "2025-04-27 20:10:17 - DataSciBench - INFO - Checkpoint saved to ./checkpoints/no_code_example.json\n",
      "2025-04-27 20:10:17 - DataSciBench - INFO - Calling LLM API with a message (total length: ~56 chars)\n",
      "2025-04-27 20:10:20 - DataSciBench - INFO - LLM API call successful on attempt 1\n",
      "2025-04-27 20:10:20 - DataSciBench - INFO - Checkpoint saved to ./checkpoints/no_code_example.json\n",
      "2025-04-27 20:10:20 - DataSciBench - INFO - Calling LLM API with a message (total length: ~46 chars)\n",
      "2025-04-27 20:10:23 - DataSciBench - INFO - LLM API call successful on attempt 1\n",
      "2025-04-27 20:10:23 - DataSciBench - INFO - Checkpoint saved to ./checkpoints/no_code_example.json\n",
      "responses are actually the same as interactor.messages\n",
      "responses == interactor.messages:  True\n",
      "\n",
      "Conversation history:\n",
      "\n",
      "[USER]:\n",
      "Hello! Can you briefly explain what quantum computing is?...\n",
      "\n",
      "[ASSISTANT]:\n",
      "Quantum computing is a new type of computing that uses the principles of quantum mechanics (the phys...\n",
      "\n",
      "[USER]:\n",
      "Can you give me a simple example of a quantum algorithm?...\n",
      "\n",
      "[ASSISTANT]:\n",
      "A very simple example of a quantum algorithm is **Deutsch's Algorithm**. It's more of a conceptual d...\n",
      "\n",
      "[USER]:\n",
      "How does that differ from classical computing?...\n",
      "\n",
      "[ASSISTANT]:\n",
      "The key differences between quantum computing and classical computing lie in how they store and proc...\n",
      "2025-04-27 20:10:23 - DataSciBench - INFO - Checkpoint saved to ./checkpoints/no_code_example.json\n",
      "\n",
      "Checkpoint saved to ./checkpoints/no_code_example.json\n"
     ]
    }
   ],
   "source": [
    "# Run the example without code execution\n",
    "try:\n",
    "    example_without_code_execution()\n",
    "except Exception as e:\n",
    "    print(f\"Error in non-code example: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74485e54",
   "metadata": {},
   "source": [
    "## Example 2: LLMInteractor with code execution\n",
    "\n",
    "This example uses open-interpreter to execute code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82c773e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_with_code_execution():\n",
    "    \"\"\"\n",
    "    Example of using LLMInteractor with code execution.\n",
    "    Uses open-interpreter to execute code.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Example: LLMInteractor with code execution ===\")\n",
    "\n",
    "    # Load configuration from TOML file\n",
    "    config = LLMConfig.from_toml(\"./llm_config.toml\")\n",
    "\n",
    "    # Enable code execution for this example\n",
    "    config.run_code = True\n",
    "    config.checkpoint_path = \"./checkpoints/code_execution_example.json\"\n",
    "\n",
    "    # Initialize with interpreter config\n",
    "    interpreter_config_path = \"./interpreter_config.toml\"\n",
    "    interactor = LLMInteractor(config, interpreter_config_path=interpreter_config_path)\n",
    "\n",
    "    # Send messages with coding tasks\n",
    "    messages = [\n",
    "        \"Generate a python function to calculate the Fibonacci sequence up to n terms. Then run it with n=10. Your code will be executed and I'll give you the print result on the console.\",\n",
    "        \"What is the time complexity of your implementation?\",\n",
    "    ]\n",
    "\n",
    "    responses = interactor.send_all(messages)\n",
    "\n",
    "    print(\"responses are actually the same as interactor.messages\")\n",
    "    print(\"responses == interactor.messages: \", responses == interactor.messages)\n",
    "\n",
    "    # Print summary of conversation\n",
    "    print(\"\\nCode execution completed. Check the full conversation in the checkpoint file.\")\n",
    "    print(f\"Checkpoint saved to {config.checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9fcbd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Example: LLMInteractor with code execution ===\n",
      "2025-04-27 21:44:10 - DataSciBench - INFO - Loaded configuration from ./llm_config.toml\n",
      "2025-04-27 21:44:10 - DataSciBench - INFO - Initialized LLMInteractor with model: gemini/gemini-2.0-flash-lite, temperature: 0.4\n",
      "2025-04-27 21:44:10 - DataSciBench - INFO - Sending 1 messages to LLM\n",
      "2025-04-27 21:44:10 - DataSciBench - INFO - Checkpoint saved to ./checkpoints/test.json\n",
      "2025-04-27 21:44:10 - DataSciBench - INFO - Calling LLM API with a message (total length: ~40 chars)\n",
      "2025-04-27 21:44:11 - DataSciBench - INFO - LLM API call successful on attempt 1\n",
      "2025-04-27 21:44:11 - DataSciBench - INFO - Checkpoint saved to ./checkpoints/test.json\n",
      "responses are actually the same as interactor.messages\n",
      "responses == interactor.messages:  True\n",
      "\n",
      "Code execution completed. Check the full conversation in the checkpoint file.\n",
      "Checkpoint saved to ./checkpoints/test.json\n"
     ]
    }
   ],
   "source": [
    "# Run the example with code execution\n",
    "try:\n",
    "    example_with_code_execution()\n",
    "except Exception as e:\n",
    "    print(f\"Error in code execution example: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b84ac4",
   "metadata": {},
   "source": [
    "## Example 3: Loading from checkpoint\n",
    "\n",
    "This example loads a conversation from a checkpoint file and continues it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7923001f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_load_from_checkpoint():\n",
    "    \"\"\"\n",
    "    Example of loading conversation from a checkpoint file and continuing it.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Example: Loading from checkpoint ===\")\n",
    "\n",
    "    # create interactor wtih checkpoint\n",
    "    checkpoints_path = \"./checkpoints/no_code_example.json\"\n",
    "    interactor = LLMInteractor.load_from_checkpoint(checkpoints_path)\n",
    "    print(f\"Loaded checkpoint from {checkpoints_path}\")\n",
    "    print(\"Current conversation history:\")\n",
    "    for i, msg in enumerate(interactor.messages):\n",
    "        role = msg[\"role\"]\n",
    "        content = msg[\"content\"]\n",
    "        print(f\"\\n[{role.upper()}]:\\n{content[:100]}...\")  # Show first 100 chars\n",
    "\n",
    "    # change the checkpoint path\n",
    "    interactor.config.checkpoint_path = \"./checkpoints/continue_example.json\"\n",
    "    # Add a new message to the conversation\n",
    "    new_messages = [\"Can you summarize the conversation so far?\", \"Have a great day!\"]\n",
    "    interactor.send_all(new_messages)\n",
    "    print(\"New messages added to the conversation.\")\n",
    "    print(\"Updated conversation history:\")\n",
    "    for i, msg in enumerate(interactor.messages):\n",
    "        role = msg[\"role\"]\n",
    "        content = msg[\"content\"]\n",
    "        print(f\"\\n[{role.upper()}]:\\n{content[:100]}...\")  # Show first 100 chars\n",
    "    # Save the updated conversation to a new checkpoint (this happens automatically during send_all, but can be called manually)\n",
    "    interactor.store_checkpoint()\n",
    "    print(f\"\\nCheckpoint saved to {interactor.config.checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b35c1d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Example: Loading from checkpoint ===\n",
      "2025-04-27 20:34:44 - DataSciBench - INFO - Initialized LLMInteractor with model: gemini/gemini-2.0-flash-lite, temperature: 0.4\n",
      "2025-04-27 20:34:44 - DataSciBench - INFO - Loaded checkpoint from ./checkpoints/no_code_example.json\n",
      "Loaded checkpoint from ./checkpoints/no_code_example.json\n",
      "Current conversation history:\n",
      "\n",
      "[USER]:\n",
      "Hello! Can you briefly explain what quantum computing is?...\n",
      "\n",
      "[ASSISTANT]:\n",
      "Quantum computing is a new type of computing that uses the principles of quantum mechanics (the phys...\n",
      "\n",
      "[USER]:\n",
      "Can you give me a simple example of a quantum algorithm?...\n",
      "\n",
      "[ASSISTANT]:\n",
      "A very simple example of a quantum algorithm is **Deutsch's Algorithm**. It's more of a conceptual d...\n",
      "\n",
      "[USER]:\n",
      "How does that differ from classical computing?...\n",
      "\n",
      "[ASSISTANT]:\n",
      "The key differences between quantum computing and classical computing lie in how they store and proc...\n",
      "2025-04-27 20:34:44 - DataSciBench - INFO - Sending 2 messages to LLM\n",
      "2025-04-27 20:34:44 - DataSciBench - INFO - Checkpoint saved to ./checkpoints/continue_example.json\n",
      "2025-04-27 20:34:44 - DataSciBench - INFO - Calling LLM API with a message (total length: ~42 chars)\n",
      "2025-04-27 20:34:45 - DataSciBench - INFO - LLM API call successful on attempt 1\n",
      "2025-04-27 20:34:45 - DataSciBench - INFO - Checkpoint saved to ./checkpoints/continue_example.json\n",
      "2025-04-27 20:34:45 - DataSciBench - INFO - Calling LLM API with a message (total length: ~17 chars)\n",
      "2025-04-27 20:34:46 - DataSciBench - INFO - LLM API call successful on attempt 1\n",
      "2025-04-27 20:34:46 - DataSciBench - INFO - Checkpoint saved to ./checkpoints/continue_example.json\n",
      "New messages added to the conversation.\n",
      "Updated conversation history:\n",
      "\n",
      "[USER]:\n",
      "Hello! Can you briefly explain what quantum computing is?...\n",
      "\n",
      "[ASSISTANT]:\n",
      "Quantum computing is a new type of computing that uses the principles of quantum mechanics (the phys...\n",
      "\n",
      "[USER]:\n",
      "Can you give me a simple example of a quantum algorithm?...\n",
      "\n",
      "[ASSISTANT]:\n",
      "A very simple example of a quantum algorithm is **Deutsch's Algorithm**. It's more of a conceptual d...\n",
      "\n",
      "[USER]:\n",
      "How does that differ from classical computing?...\n",
      "\n",
      "[ASSISTANT]:\n",
      "The key differences between quantum computing and classical computing lie in how they store and proc...\n",
      "\n",
      "[USER]:\n",
      "Can you summarize the conversation so far?...\n",
      "\n",
      "[ASSISTANT]:\n",
      "We've discussed the basics of quantum computing:\n",
      "\n",
      "*   **What it is:** A new type of computing that u...\n",
      "\n",
      "[USER]:\n",
      "Have a great day!...\n",
      "\n",
      "[ASSISTANT]:\n",
      "You too! Have a fantastic day!\n",
      "...\n",
      "2025-04-27 20:34:46 - DataSciBench - INFO - Checkpoint saved to ./checkpoints/continue_example.json\n",
      "\n",
      "Checkpoint saved to ./checkpoints/continue_example.json\n"
     ]
    }
   ],
   "source": [
    "# Run the example loading from checkpoint\n",
    "try:\n",
    "    example_load_from_checkpoint()\n",
    "except Exception as e:\n",
    "    print(f\"Error in checkpoint loading example: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
