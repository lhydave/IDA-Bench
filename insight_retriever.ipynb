{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any, Optional\n",
    "from copy import deepcopy\n",
    "from llms.llm_interact import LLMConfig\n",
    "from llms.retriever import Retriever\n",
    "from llm_interact_env import Environment, EnvironmentConfig, Task, run\n",
    "from logger import logger, configure_global_logger  # Import the logger\n",
    "import subprocess  # Added for running the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-13 10:50:41 - DataSciBench - INFO - Loaded configuration from llm_configs/raw/llm_config_retriever.toml\n",
      "2025-05-13 10:50:41 - DataSciBench - INFO - Initialized Gatekeeper with model: litellm_proxy/claude-3-7-sonnet, temperature: 1\n"
     ]
    }
   ],
   "source": [
    "retriever_config = LLMConfig.from_toml(\"llm_configs/raw/llm_config_retriever.toml\")\n",
    "\n",
    "retriever = Retriever(retriever_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 instruction files\n",
      "Processing: benchmark_final/storage/aarthi93-end-to-end-ml-pipeline/instructions/instructions.md\n",
      "Project: aarthi93-end-to-end-ml-pipeline\n",
      "Response: # House Price Prediction Reference Insights\n",
      "\n",
      "Background:\n",
      "The dataset contains housing information split into train.csv (with target prices) and test.csv (without targets) for evaluating predictions. The data is housed in '/app/datasets' with a required submission format matching sample_submission.csv.\n",
      "\n",
      "Goal:\n",
      "Predict house sale prices (SalePrice).\n",
      "\n",
      "Metric:\n",
      "Multiple evaluation metrics are used: RMSE, MAE, and R² to assess model performance from different perspectives.\n",
      "\n",
      "Reference insights:\n",
      "- Drop columns with high missing value percentages (Alley: 93%, Pool QC: 99%, Fence: 80%, Misc Feature: 96%) rather than attempting imputation.\n",
      "- Create meaningful age-related features (House_Age, Years_Since_Remodel) using a reference year, as time-based features are important for price prediction.\n",
      "- Use different preprocessing strategies for different feature types: median imputation with scaling for numeric features, 'None' imputation with one-hot encoding for categorical features.\n",
      "- Create combined features like total bathroom count (weighting half baths as 0.5 of full baths) and binary indicators (Has_Pool) which may be more predictive than raw measurements.\n",
      "- Remove temporal features like 'Mo Sold' and 'Yr Sold' to prevent data leakage that could lead to unrealistic model performance.\n",
      "- Random Forest models with moderate complexity (n_estimators=150, max_depth=30, min_samples_split=5) perform well for this housing price prediction task.\n",
      "- Evaluate the model using both absolute error measures (RMSE, MAE) for practical interpretation and relative measures (R²) for statistical assessment.\n",
      "--------------------------------------------------\n",
      "Saved reference insights to: benchmark_final/storage/aarthi93-end-to-end-ml-pipeline/instructions/reference_insights.md\n",
      "Processing: benchmark_final/storage/abdallaellaithy-titanic-in-space-ml-survival-predictions/instructions/instructions.md\n",
      "Project: abdallaellaithy-titanic-in-space-ml-survival-predictions\n",
      "Response: Background:\n",
      "The Spaceship Titanic dataset contains passenger information, likely structured similarly to the historical Titanic dataset but in a science fiction context.\n",
      "\n",
      "Goal:\n",
      "Predict which passengers were transported to an alternate dimension.\n",
      "\n",
      "Metric:\n",
      "ROC AUC is the primary evaluation metric.\n",
      "\n",
      "Reference insights:\n",
      "- The problem is a binary classification task, not a regression problem.\n",
      "- Parse Cabin information into three components (Deck, Number, Side) to capture spatial influences.\n",
      "- Create 'PassengerGroup' and 'IsAlone' features as group dynamics may influence transportation outcomes.\n",
      "- Aggregate spending features into 'TotalSpend' and create a binary 'HasSpent' indicator.\n",
      "- Fill missing spending values with zeros (assume missing = no spending).\n",
      "- Use stratified sampling for train-test splitting and cross-validation to maintain class distribution.\n",
      "- Tree-based models perform well; tune parameters controlling model complexity (depth, samples per split) and ensemble strength (estimators, learning rate).\n",
      "- Convert final predictions to boolean type before submission.\n",
      "--------------------------------------------------\n",
      "Saved reference insights to: benchmark_final/storage/abdallaellaithy-titanic-in-space-ml-survival-predictions/instructions/reference_insights.md\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from pathlib import Path\n",
    "import os\n",
    "# Find all instruction.md files in the storage directory\n",
    "storage_dir = \"benchmark_final/storage\"\n",
    "instruction_files = []\n",
    "\n",
    "# Walk through all directories under storage\n",
    "for root, dirs, files in os.walk(storage_dir):\n",
    "    # Check if this is an 'instructions' directory\n",
    "    if os.path.basename(root) == \"instructions\":\n",
    "        # Look for instructions.md file\n",
    "        instruction_file = os.path.join(root, \"instructions.md\")\n",
    "        if os.path.exists(instruction_file):\n",
    "            instruction_files.append(instruction_file)\n",
    "\n",
    "print(f\"Found {len(instruction_files)} instruction files\")\n",
    "\n",
    "# Process each instruction file\n",
    "for instruction_file in instruction_files:\n",
    "    print(f\"Processing: {instruction_file}\")\n",
    "    \n",
    "    # Load the instruction content\n",
    "    with open(instruction_file, \"r\") as f:\n",
    "        instruction_content = f.read()\n",
    "    \n",
    "    # Call the retriever with the instruction content\n",
    "    response = retriever.call_llm(instruction_content, thinking={\"type\": \"enabled\", \"budget_tokens\": 4096})\n",
    "    # Print the project name and response\n",
    "    project_name = Path(instruction_file).parts[-3]  # Get the project name from the path\n",
    "    print(f\"Project: {project_name}\")\n",
    "    print(f\"Response: {response}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Extract the objective from the instruction content\n",
    "    import re\n",
    "    objective_match = re.search(r'\\*\\*Objective\\*\\*(.*?)(?=\\*\\*)', instruction_content, re.DOTALL)\n",
    "    objective_text = \"\"\n",
    "    if objective_match:\n",
    "        objective_text = objective_match.group(1).strip() + \"\\n\\n\"\n",
    "    \n",
    "    # Save the response to reference_insights file in the same directory as instructions.md\n",
    "    reference_insights_path = os.path.join(os.path.dirname(instruction_file), \"reference_insights.md\")\n",
    "    with open(reference_insights_path, \"w\") as f:\n",
    "        f.write(objective_text + response)\n",
    "    print(f\"Saved reference insights to: {reference_insights_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
