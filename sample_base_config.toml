# Sample base_config.toml file for the LLM benchmarking framework
# This is for instructor and supervisor agents
[llm]
api_key = "your-api-key-here"
model = "gpt-3.5-turbo"

# Optional parameters with defaults
temperature = 0.0
max_retries = 3
retry_delay = 2
run_code = false
api_base = "https://api.openai.com/v1"  # Optional custom API endpoint

# Rate limiting options
rpm = 60  # Default requests per minute limit
adaptive_rate_limit = true  # Automatically adjust rate limits based on API responses

# Model-specific RPM limits
# This will override the default RPM for specific models
[rpm_per_model]
"gpt-3.5-turbo" = 60
"gpt-4" = 30
"gpt-4-turbo" = 40
"claude-3-sonnet" = 20 


# benchmarking options
[benchmark]
benchmark_dir = "./data/benchmarks/"
dataset_dir = "./data/datasets/"
checkpoint_path = "./checkpoints/"
results = "./results/"
log_path = "./logs/"
max_workers = 8
# uncomment it if you only want to run a subset of the test cases
# test_cases = ["test_case_1", "test_case_2", "test_case_3"]
