# sample configuration file for the agent to be tested in the benchmark

# unique identifier for the agent
id = "your-agent-id"
# For the configuration of api_base, api_key, model, please visit https://docs.litellm.ai/docs/providers for more details.
# for most model providers, the api_base is an optional parameter
# api_base = "http://your/api/base"
api_key = "your-api-key"
model = "your/model-name"
temperature = 0.4
# if an llm API call fails, it will retry max_retries many times
max_retries = 3
# if an llm API call fails, it will wait retry_delay long (in seconds) before retrying
# The waiting time will increase exponentially with each failure.
# For example: if another failure occurs, it will wait 2 * retry_delay before retrying again, and so on
retry_delay = 30
# this is for agent framework, for now, we only support "base-agent"
framework = "base-agent"
