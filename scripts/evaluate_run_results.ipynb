{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_timestamp_from_filename(filename):\n",
    "    \"\"\"Extract timestamp from filename.\n",
    "    Expected format: *_YYYYMMDD_HHMMSS.json\"\"\"\n",
    "    match = re.search(r\"_(\\d{8}_\\d{6})\\.json$\", filename)\n",
    "    if match:\n",
    "        timestamp_str = match.group(1)\n",
    "        return timestamp_str\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_failed(result_dict):\n",
    "    \"\"\"Check if a result represents a failed run.\n",
    "    Failed if skill_score is -10000, nan, or missing.\"\"\"\n",
    "    try:\n",
    "        skill_score = result_dict.get(\"metrics\", {}).get(\"skill_score\")\n",
    "        return (\n",
    "            skill_score == -10000 or (isinstance(skill_score, float) and np.isnan(skill_score)) or skill_score is None\n",
    "        )\n",
    "    except Exception:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing abdallaellaithy-titanic-in-space-ml-survival-predictions_claude-3-7-sonnet_20250514_182315.json: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing abdallaellaithy-titanic-in-space-ml-survival-predictions_deepseek-r1_20250514_165611.json: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing sudalairajkumar-simple-feature-engg-notebook-spooky-author_o3_20250514_185710.json: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing abdallaellaithy-titanic-in-space-ml-survival-predictions_claude-3-7-sonnet_20250514_182908.json: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing sudalairajkumar-simple-feature-engg-notebook-spooky-author_o3_20250514_185555.json: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing abdallaellaithy-titanic-in-space-ml-survival-predictions_deepseek-v3_20250514_165611.json: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing abdallaellaithy-titanic-in-space-ml-survival-predictions_claude-3-7-sonnet_20250514_175357.json: Expecting value: line 1 column 1 (char 0)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the results list\n",
    "all_results = []\n",
    "\n",
    "# Process all JSON files in the results directory\n",
    "results_dir = \"experiments/results\"\n",
    "for filename in os.listdir(results_dir):\n",
    "    if filename.endswith(\".json\") and filename != \"summary.json\" and filename != \"evaluation_only_summary.json\":\n",
    "        file_path = os.path.join(results_dir, filename)\n",
    "\n",
    "        try:\n",
    "            with open(file_path) as f:\n",
    "                result_dict = json.load(f)\n",
    "\n",
    "            # Add timestamp and failed status\n",
    "            timestamp = parse_timestamp_from_filename(filename)\n",
    "            if timestamp:\n",
    "                result_dict[\"timestamp\"] = timestamp\n",
    "                result_dict[\"failed\"] = is_failed(result_dict)\n",
    "                all_results.append(result_dict)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results processed: 128\n",
      "\n",
      "Sample result:\n",
      "{\n",
      "  \"benchmark_id\": \"ugurcan95-brazilian-tweet-sentiment-analysis\",\n",
      "  \"agent_id\": \"litellm_proxy/deepseek-r1\",\n",
      "  \"completion_status\": \"completed\",\n",
      "  \"metrics\": {\n",
      "    \"interaction_time_seconds\": 505.785724,\n",
      "    \"conversation_turns\": 8,\n",
      "    \"code_snippets_count\": 5,\n",
      "    \"total_code_executions\": 5,\n",
      "    \"code_operations\": {\n",
      "      \"pandas_operations\": 10,\n",
      "      \"plotting\": 0,\n",
      "      \"dataframe_creation\": 0,\n",
      "      \"file_io\": 4,\n",
      "      \"error_handling\": 0,\n",
      "      \"loops\": 3,\n",
      "      \"functions\": 3,\n",
      "      \"imports\": 22,\n",
      "      \"error_count\": 2\n",
      "    },\n",
      "    \"absolute_metric_score\": 0.7493333333333333,\n",
      "    \"skill_score\": 0.020067761271826905\n",
      "  },\n",
      "  \"timestamp\": \"20250513_144422\",\n",
      "  \"failed\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Display the number of results processed\n",
    "print(f\"Total results processed: {len(all_results)}\")\n",
    "\n",
    "# Display a sample result\n",
    "if all_results:\n",
    "    print(\"\\nSample result:\")\n",
    "    print(json.dumps(all_results[0], indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find out competition/non-competition notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 competition benchmarks:\n",
      "- vijaythurimella-bank-subscriptions-predictions-f1-score\n",
      "- patilaakash619-backpack-price-prediction-ml-guide\n",
      "- esotericdata1-titanickaggle-ds\n",
      "- dmytrobuhai-eda-rf\n",
      "- jakubkrasuski-llm-chatbot-arena-predicting-user-preferences\n",
      "- ugurcan95-brazilian-tweet-sentiment-analysis\n",
      "- abdallaellaithy-titanic-in-space-ml-survival-predictions\n",
      "- shaswatatripathy-store-sales-prediction\n",
      "- jakubkrasuski-store-sales-forecasting-modeling-with-lightgbm\n",
      "- mightyjiraiya-titanic-survival-prediction\n",
      "- iseedeep-mission-podcast-listening-prediction\n",
      "- jimmyyeung-spaceship-titanic-xgb-top5\n",
      "- tetsutani-ps3e9-eda-and-gbdt-catboost-median-duplicatedata\n",
      "- slimreaper-random-forest-xgb-catboost-ensemble-t40\n",
      "- sudalairajkumar-simple-feature-engg-notebook-spooky-author\n",
      "- mohitsital-top-10-bike-sharing-rf-gbm\n",
      "\n",
      "Found 10 non-competition benchmarks:\n",
      "- sasakitetsuya-predicting-startup-valuation-with-machine-learning\n",
      "- drpashamd4r-indian-floods-data-exploratory\n",
      "- umerhayat123-how-i-achieved-83-accuracy\n",
      "- aarthi93-end-to-end-ml-pipeline\n",
      "- ak5047-australia-weather\n",
      "- ayodejiibrahimlateef-integrative-analysis-early-depression-detection\n",
      "- hanymato-mobile-price-prediction-model\n",
      "- amitsinghbhadoria0-final-qt-project-analysis\n",
      "- patilaakash619-electric-vehicle-population-data-in-the-us\n",
      "- hasangulec-feature-engineering-diabetes\n"
     ]
    }
   ],
   "source": [
    "# Get all benchmark IDs from the notebook files\n",
    "competition_notebooks_dir = \"benchmark_data_toSubmit/notebooks/storage\"\n",
    "competition_benchmark = []\n",
    "\n",
    "# Pattern to convert filenames to benchmark IDs\n",
    "# Replace ##### with - in filenames\n",
    "notebook_files = os.listdir(competition_notebooks_dir)\n",
    "for notebook_file in notebook_files:\n",
    "    if notebook_file.endswith(\".ipynb\"):\n",
    "        # Convert filename to benchmark_id (replace ##### with -)\n",
    "        benchmark_id = notebook_file[:-6].replace(\"#####\", \"-\")\n",
    "        competition_benchmark.append(benchmark_id)\n",
    "\n",
    "competition_notebooks_dir = \"test_data/notebooks/storage\"\n",
    "notebook_files = os.listdir(competition_notebooks_dir)\n",
    "for notebook_file in notebook_files:\n",
    "    if notebook_file.endswith(\".ipynb\"):\n",
    "        # Convert filename to benchmark_id (replace ##### with -)\n",
    "        benchmark_id = notebook_file[:-6].replace(\"#####\", \"-\")\n",
    "        competition_benchmark.append(benchmark_id)\n",
    "\n",
    "# Print the competition benchmarks\n",
    "print(f\"Found {len(competition_benchmark)} competition benchmarks:\")\n",
    "for benchmark in competition_benchmark:\n",
    "    print(f\"- {benchmark}\")\n",
    "\n",
    "# Create the noncompetition_benchmark list\n",
    "# This includes benchmark_ids in all_results that aren't in competition_benchmark\n",
    "noncompetition_benchmark = []\n",
    "\n",
    "# Get unique benchmark_ids from all_results\n",
    "benchmark_dir = \"benchmark_final/storage\"\n",
    "all_benchmark_ids = []\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.exists(benchmark_dir) and os.path.isdir(benchmark_dir):\n",
    "    for benchmark_folder in os.listdir(benchmark_dir):\n",
    "        # Assume each benchmark_id has a corresponding subdirectory\n",
    "        if os.path.isdir(os.path.join(benchmark_dir, benchmark_folder)):\n",
    "            all_benchmark_ids.append(benchmark_folder)\n",
    "else:\n",
    "    print(f\"Warning: Directory {benchmark_dir} does not exist or is not a directory!\")\n",
    "all_benchmark_ids = set(all_benchmark_ids)\n",
    "\n",
    "\n",
    "# Find benchmarks that aren't in the competition list\n",
    "for benchmark_id in all_benchmark_ids:\n",
    "    if benchmark_id not in competition_benchmark:\n",
    "        noncompetition_benchmark.append(benchmark_id)\n",
    "\n",
    "# Print the non-competition benchmarks\n",
    "print(f\"\\nFound {len(noncompetition_benchmark)} non-competition benchmarks:\")\n",
    "for benchmark in noncompetition_benchmark:\n",
    "    print(f\"- {benchmark}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_benchmark_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find out the latest result for one agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23 latest unfailed results between 20250514_000000 and 20250514_235959\n"
     ]
    }
   ],
   "source": [
    "def find_latest_unfailed_result_for_agent(agent_id, start_timestamp=None, end_timestamp=None, file_path=\"experiments\"):\n",
    "    \"\"\"\n",
    "    Find the latest unfailed result for each benchmark_id for a given agent_id within a timestamp range.\n",
    "    A result is considered unfailed if the corresponding log file contains \"Runner script completed\".\n",
    "\n",
    "    Args:\n",
    "        agent_id (str): The ID of the agent to search for\n",
    "        start_timestamp (str): Optional start of timestamp range in format YYYYMMDD_HHMMSS\n",
    "        end_timestamp (str): Optional end of timestamp range in format YYYYMMDD_HHMMSS\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries containing the latest unfailed results for each benchmark\n",
    "    \"\"\"\n",
    "    # Dictionary to store the latest unfailed result for each benchmark_id\n",
    "    latest_unfailed_results = {}\n",
    "\n",
    "    # Convert timestamp strings to datetime objects if provided\n",
    "    start_time = None\n",
    "    end_time = None\n",
    "    if start_timestamp:\n",
    "        start_time = datetime.strptime(start_timestamp, \"%Y%m%d_%H%M%S\")\n",
    "    if end_timestamp:\n",
    "        end_time = datetime.strptime(end_timestamp, \"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    # Process all JSON files in the results directory\n",
    "    results_dir = f\"{file_path}/results\"\n",
    "    for filename in os.listdir(results_dir):\n",
    "        if filename.endswith(\".json\") and filename != \"summary.json\" and filename != \"evaluation_only_summary.json\":\n",
    "            f_path = os.path.join(results_dir, filename)\n",
    "\n",
    "            try:\n",
    "                with open(f_path) as f:\n",
    "                    result_dict = json.load(f)\n",
    "\n",
    "                # Add timestamp and failed status\n",
    "                timestamp = parse_timestamp_from_filename(filename)\n",
    "                if timestamp:\n",
    "                    result_dict[\"timestamp\"] = timestamp\n",
    "                    result_dict[\"failed\"] = is_failed(result_dict)\n",
    "                    all_results.append(result_dict)\n",
    "            except Exception:\n",
    "                # print(f\"Error processing {filename}: {str(e)}\")\n",
    "                pass\n",
    "\n",
    "    # Iterate through all results\n",
    "    for result in all_results:\n",
    "        # Skip if this result is not from the specified agent\n",
    "        if agent_id not in result.get(\"agent_id\"):\n",
    "            continue\n",
    "\n",
    "        benchmark_id = result.get(\"benchmark_id\")\n",
    "        if not benchmark_id:\n",
    "            continue\n",
    "        result_time = None\n",
    "        # Check if the result is within the timestamp range\n",
    "        if result.get(\"timestamp\"):\n",
    "            # Convert timestamp to datetime object for comparison\n",
    "            if isinstance(result[\"timestamp\"], str):\n",
    "                try:\n",
    "                    result_time = datetime.strptime(result[\"timestamp\"], \"%Y%m%d_%H%M%S\")\n",
    "                except ValueError:\n",
    "                    # If timestamp format is different, skip this result\n",
    "                    continue\n",
    "            else:\n",
    "                # If timestamp is already a datetime object\n",
    "                result_time = result[\"timestamp\"]\n",
    "\n",
    "            # Skip if the result is outside the specified time range\n",
    "            if (start_time and result_time < start_time) or (end_time and result_time > end_time):\n",
    "                continue\n",
    "\n",
    "        # Check if the run was completed successfully by examining the log file\n",
    "        log_file_path = f\"{file_path}/logs/{benchmark_id}_{agent_id.replace('/', '_')}_{result['timestamp']}.log\"\n",
    "        if os.path.exists(log_file_path):\n",
    "            try:\n",
    "                with open(log_file_path, errors=\"ignore\") as f:\n",
    "                    log_content = f.read()\n",
    "                    if \"Runner script completed\" not in log_content:\n",
    "                        # Skip this result if the run didn't complete successfully\n",
    "                        continue\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not read log file {log_file_path}: {e}\")\n",
    "                # Skip if we can't verify completion\n",
    "                continue\n",
    "        else:\n",
    "            # If the log file doesn't exist, we can't verify completion\n",
    "            print(f\"Warning: Log file not found: {log_file_path}\")\n",
    "            continue\n",
    "\n",
    "        # If we haven't seen this benchmark_id before, or if this result is newer\n",
    "        if (\n",
    "            benchmark_id not in latest_unfailed_results\n",
    "            or result_time > latest_unfailed_results[benchmark_id][\"timestamp\"]\n",
    "        ):\n",
    "            # Store the result with the datetime object for easier comparison later\n",
    "            result[\"timestamp\"] = result_time\n",
    "            latest_unfailed_results[benchmark_id] = result\n",
    "\n",
    "    # Convert the dictionary values to a list and restore string timestamps\n",
    "    result_list = list(latest_unfailed_results.values())\n",
    "    for result in result_list:\n",
    "        # Convert datetime back to string for consistency\n",
    "        if isinstance(result[\"timestamp\"], datetime):\n",
    "            result[\"timestamp\"] = result[\"timestamp\"].strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    return result_list\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "start_time = \"20250514_000000\"  # Optional: start of time range\n",
    "end_time = \"20250514_235959\"  # Optional: end of time range\n",
    "file_path = \"experiments_old_version\"\n",
    "latest_unfailed_results = find_latest_unfailed_result_for_agent(\"deepseek-v3\", start_time, end_time, file_path)\n",
    "print(f\"Found {len(latest_unfailed_results)} latest unfailed results between {start_time} and {end_time}\")\n",
    "# if latest_unfailed_results:\n",
    "#     print(\"\\nSample latest unfailed result:\")\n",
    "#     print(json.dumps(latest_unfailed_results[0], indent=2, default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing benchmark_ids for deepseek-v3:\n",
      "set()\n",
      "\n",
      "\n",
      "proportion of positive skill scores\n",
      "deepseek-v3:  0.46153846153846156\n",
      "\n",
      "\n",
      "proportion of failed runs\n",
      "deepseek-v3:  0.23076923076923078\n",
      "\n",
      "\n",
      "average skill score of non-failed runs\n",
      "deepseek-v3:  -0.32349105923185995\n",
      "\n",
      "\n",
      "proportion of positive skill scores among non-failed runs\n",
      "deepseek-v3:  0.6\n",
      "\n",
      "\n",
      "proportion of positive skill scores among non-competition benchmarks\n",
      "deepseek-v3:  0.5\n",
      "\n",
      "\n",
      "proportion of positive skill scores among competition benchmarks\n",
      "deepseek-v3:  0.4375\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def analyze_agent_results(\n",
    "    agent_name,\n",
    "    file_path=\"experiments_old_version\",\n",
    "    all_benchmark_ids=None,\n",
    "    competition_benchmark=None,\n",
    "    skill_score_threshold=-0.05,\n",
    "):\n",
    "    results = find_latest_unfailed_result_for_agent(agent_name, file_path=file_path)\n",
    "\n",
    "    if all_benchmark_ids is not None:\n",
    "        missing = set(all_benchmark_ids) - set([i[\"benchmark_id\"] for i in results])\n",
    "        print(f\"Missing benchmark_ids for {agent_name}:\")\n",
    "        print(missing)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    failed_flags = np.array([i[\"failed\"] for i in results])\n",
    "    skill_scores = np.array([i[\"metrics\"][\"skill_score\"] for i in results])\n",
    "\n",
    "    print(\"proportion of positive skill scores\")\n",
    "    print(f\"{agent_name}: \", np.sum(skill_scores >= skill_score_threshold) / len(skill_scores))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"proportion of failed runs\")\n",
    "    print(f\"{agent_name}: \", np.sum(failed_flags) / len(failed_flags))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"average skill score of non-failed runs\")\n",
    "    print(f\"{agent_name}: \", np.mean(skill_scores[~failed_flags]))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"proportion of positive skill scores among non-failed runs\")\n",
    "    print(\n",
    "        f\"{agent_name}: \",\n",
    "        np.sum(skill_scores[~failed_flags] >= skill_score_threshold) / len(skill_scores[~failed_flags]),\n",
    "    )\n",
    "    print(\"\\n\")\n",
    "\n",
    "    if competition_benchmark is not None:\n",
    "        is_competition = np.array([i[\"benchmark_id\"] in competition_benchmark for i in results])\n",
    "        is_non_competition = ~is_competition\n",
    "\n",
    "        print(\"proportion of positive skill scores among non-competition benchmarks\")\n",
    "        print(\n",
    "            f\"{agent_name}: \",\n",
    "            np.sum(skill_scores[is_non_competition] >= skill_score_threshold) / np.sum(is_non_competition),\n",
    "        )\n",
    "        print(\"\\n\")\n",
    "\n",
    "        print(\"proportion of positive skill scores among competition benchmarks\")\n",
    "        print(f\"{agent_name}: \", np.sum(skill_scores[is_competition] >= skill_score_threshold) / np.sum(is_competition))\n",
    "        print(\"\\n\")\n",
    "    return results\n",
    "\n",
    "\n",
    "results_deepseek_v3 = analyze_agent_results(\n",
    "    agent_name=\"deepseek-v3\",\n",
    "    all_benchmark_ids=all_benchmark_ids,\n",
    "    competition_benchmark=competition_benchmark,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'benchmark_id': 'tetsutani-ps3e9-eda-and-gbdt-catboost-median-duplicatedata',\n",
       "  'agent_id': 'litellm_proxy/deepseek-v3',\n",
       "  'completion_status': 'completed',\n",
       "  'metrics': {'interaction_time_seconds': 590.192362,\n",
       "   'conversation_turns': 6,\n",
       "   'code_snippets_count': 7,\n",
       "   'total_code_executions': 7,\n",
       "   'code_operations': {'pandas_operations': 3,\n",
       "    'plotting': 0,\n",
       "    'dataframe_creation': 2,\n",
       "    'file_io': 4,\n",
       "    'error_handling': 0,\n",
       "    'loops': 3,\n",
       "    'functions': 2,\n",
       "    'imports': 8,\n",
       "    'error_count': 0},\n",
       "   'absolute_metric_score': 12.318180674246626,\n",
       "   'skill_score': -0.019854917317326692},\n",
       "  'timestamp': '20250514_172506',\n",
       "  'failed': False},\n",
       " {'benchmark_id': 'drpashamd4r-indian-floods-data-exploratory',\n",
       "  'agent_id': 'litellm_proxy/deepseek-v3',\n",
       "  'completion_status': 'completed',\n",
       "  'metrics': {'interaction_time_seconds': 395.499356,\n",
       "   'conversation_turns': 7,\n",
       "   'code_snippets_count': 12,\n",
       "   'total_code_executions': 12,\n",
       "   'code_operations': {'pandas_operations': 3,\n",
       "    'plotting': 0,\n",
       "    'dataframe_creation': 6,\n",
       "    'file_io': 11,\n",
       "    'error_handling': 3,\n",
       "    'loops': 25,\n",
       "    'functions': 4,\n",
       "    'imports': 6,\n",
       "    'error_count': 0},\n",
       "   'absolute_metric_score': 182.6,\n",
       "   'skill_score': 0.12391809161916827},\n",
       "  'timestamp': '20250514_172506',\n",
       "  'failed': False},\n",
       " {'benchmark_id': 'ugurcan95-brazilian-tweet-sentiment-analysis',\n",
       "  'agent_id': 'litellm_proxy/deepseek-v3',\n",
       "  'completion_status': 'completed',\n",
       "  'metrics': {'interaction_time_seconds': 339.298394,\n",
       "   'conversation_turns': 8,\n",
       "   'code_snippets_count': 8,\n",
       "   'total_code_executions': 8,\n",
       "   'code_operations': {'pandas_operations': 9,\n",
       "    'plotting': 0,\n",
       "    'dataframe_creation': 2,\n",
       "    'file_io': 4,\n",
       "    'error_handling': 3,\n",
       "    'loops': 3,\n",
       "    'functions': 3,\n",
       "    'imports': 18,\n",
       "    'error_count': 1},\n",
       "   'absolute_metric_score': 0.752,\n",
       "   'skill_score': 0.030492572322126772},\n",
       "  'timestamp': '20250514_174300',\n",
       "  'failed': False},\n",
       " {'benchmark_id': 'iseedeep-mission-podcast-listening-prediction',\n",
       "  'agent_id': 'litellm_proxy/deepseek-v3',\n",
       "  'completion_status': 'completed',\n",
       "  'metrics': {'interaction_time_seconds': 1325.992943,\n",
       "   'conversation_turns': 19,\n",
       "   'code_snippets_count': 17,\n",
       "   'total_code_executions': 17,\n",
       "   'code_operations': {'pandas_operations': 36,\n",
       "    'plotting': 0,\n",
       "    'dataframe_creation': 12,\n",
       "    'file_io': 21,\n",
       "    'error_handling': 1,\n",
       "    'loops': 3,\n",
       "    'functions': 9,\n",
       "    'imports': 14,\n",
       "    'error_count': 3},\n",
       "   'absolute_metric_score': 20.424175380356836,\n",
       "   'skill_score': -0.5615689548374548},\n",
       "  'timestamp': '20250514_174542',\n",
       "  'failed': False},\n",
       " {'benchmark_id': 'patilaakash619-electric-vehicle-population-data-in-the-us',\n",
       "  'agent_id': 'litellm_proxy/deepseek-v3',\n",
       "  'completion_status': 'completed',\n",
       "  'metrics': {'interaction_time_seconds': 223.047995,\n",
       "   'conversation_turns': 6,\n",
       "   'code_snippets_count': 7,\n",
       "   'total_code_executions': 7,\n",
       "   'code_operations': {'pandas_operations': 4,\n",
       "    'plotting': 0,\n",
       "    'dataframe_creation': 1,\n",
       "    'file_io': 3,\n",
       "    'error_handling': 0,\n",
       "    'loops': 4,\n",
       "    'functions': 2,\n",
       "    'imports': 8,\n",
       "    'error_count': 0},\n",
       "   'absolute_metric_score': 7.8632747206617255,\n",
       "   'skill_score': 0.1781896265158934},\n",
       "  'timestamp': '20250514_174405',\n",
       "  'failed': False},\n",
       " {'benchmark_id': 'hanymato-mobile-price-prediction-model',\n",
       "  'agent_id': 'litellm_proxy/deepseek-v3',\n",
       "  'completion_status': 'completed',\n",
       "  'metrics': {'interaction_time_seconds': 372.637728,\n",
       "   'conversation_turns': 12,\n",
       "   'code_snippets_count': 19,\n",
       "   'total_code_executions': 19,\n",
       "   'code_operations': {'pandas_operations': 37,\n",
       "    'plotting': 0,\n",
       "    'dataframe_creation': 3,\n",
       "    'file_io': 9,\n",
       "    'error_handling': 2,\n",
       "    'loops': 3,\n",
       "    'functions': 4,\n",
       "    'imports': 11,\n",
       "    'error_count': 0},\n",
       "   'absolute_metric_score': 984.6295977300639,\n",
       "   'skill_score': -3.7245617191026845},\n",
       "  'timestamp': '20250514_173652',\n",
       "  'failed': False},\n",
       " {'benchmark_id': 'slimreaper-random-forest-xgb-catboost-ensemble-t40',\n",
       "  'agent_id': 'litellm_proxy/deepseek-v3',\n",
       "  'completion_status': 'completed',\n",
       "  'metrics': {'interaction_time_seconds': 199.098261,\n",
       "   'conversation_turns': 6,\n",
       "   'code_snippets_count': 7,\n",
       "   'total_code_executions': 7,\n",
       "   'code_operations': {'pandas_operations': 4,\n",
       "    'plotting': 0,\n",
       "    'dataframe_creation': 1,\n",
       "    'file_io': 3,\n",
       "    'error_handling': 1,\n",
       "    'loops': 0,\n",
       "    'functions': 0,\n",
       "    'imports': 9,\n",
       "    'error_count': 0},\n",
       "   'absolute_metric_score': 0.7035512094698919,\n",
       "   'skill_score': -0.39467312348668326},\n",
       "  'timestamp': '20250514_173307',\n",
       "  'failed': False},\n",
       " {'benchmark_id': 'vijaythurimella-bank-subscriptions-predictions-f1-score',\n",
       "  'agent_id': 'litellm_proxy/deepseek-v3',\n",
       "  'completion_status': 'completed',\n",
       "  'metrics': {'interaction_time_seconds': 371.846782,\n",
       "   'conversation_turns': 8,\n",
       "   'code_snippets_count': 13,\n",
       "   'total_code_executions': 13,\n",
       "   'code_operations': {'pandas_operations': 14,\n",
       "    'plotting': 0,\n",
       "    'dataframe_creation': 1,\n",
       "    'file_io': 3,\n",
       "    'error_handling': 0,\n",
       "    'loops': 1,\n",
       "    'functions': 0,\n",
       "    'imports': 30,\n",
       "    'error_count': 0},\n",
       "   'skill_score': -10000.0},\n",
       "  'evaluation_error': 'No columns to parse from file',\n",
       "  'timestamp': '20250514_172506',\n",
       "  'failed': True},\n",
       " {'benchmark_id': 'umerhayat123-how-i-achieved-83-accuracy',\n",
       "  'agent_id': 'litellm_proxy/deepseek-v3',\n",
       "  'completion_status': 'completed',\n",
       "  'metrics': {'interaction_time_seconds': 394.334555,\n",
       "   'conversation_turns': 11,\n",
       "   'code_snippets_count': 9,\n",
       "   'total_code_executions': 9,\n",
       "   'code_operations': {'pandas_operations': 9,\n",
       "    'plotting': 0,\n",
       "    'dataframe_creation': 8,\n",
       "    'file_io': 8,\n",
       "    'error_handling': 6,\n",
       "    'loops': 13,\n",
       "    'functions': 0,\n",
       "    'imports': 13,\n",
       "    'error_count': 0},\n",
       "   'skill_score': -10000.0},\n",
       "  'evaluation_error': 'No columns to parse from file',\n",
       "  'timestamp': '20250514_174043',\n",
       "  'failed': True},\n",
       " {'benchmark_id': 'dmytrobuhai-eda-rf',\n",
       "  'agent_id': 'litellm_proxy/deepseek-v3',\n",
       "  'completion_status': 'completed',\n",
       "  'metrics': {'interaction_time_seconds': 470.000651,\n",
       "   'conversation_turns': 6,\n",
       "   'code_snippets_count': 11,\n",
       "   'total_code_executions': 11,\n",
       "   'code_operations': {'pandas_operations': 2,\n",
       "    'plotting': 0,\n",
       "    'dataframe_creation': 3,\n",
       "    'file_io': 5,\n",
       "    'error_handling': 0,\n",
       "    'loops': 2,\n",
       "    'functions': 6,\n",
       "    'imports': 9,\n",
       "    'error_count': 0},\n",
       "   'absolute_metric_score': 0.8045826713919101,\n",
       "   'skill_score': 0.425331967728604},\n",
       "  'timestamp': '20250514_172506',\n",
       "  'failed': False},\n",
       " {'benchmark_id': 'sasakitetsuya-predicting-startup-valuation-with-machine-learning',\n",
       "  'agent_id': 'litellm_proxy/deepseek-v3',\n",
       "  'completion_status': 'completed',\n",
       "  'metrics': {'interaction_time_seconds': 255.625537,\n",
       "   'conversation_turns': 9,\n",
       "   'code_snippets_count': 7,\n",
       "   'total_code_executions': 7,\n",
       "   'code_operations': {'pandas_operations': 11,\n",
       "    'plotting': 0,\n",
       "    'dataframe_creation': 1,\n",
       "    'file_io': 9,\n",
       "    'error_handling': 1,\n",
       "    'loops': 4,\n",
       "    'functions': 2,\n",
       "    'imports': 16,\n",
       "    'error_count': 0},\n",
       "   'absolute_metric_score': 0.299477690994905,\n",
       "   'skill_score': -0.004084683819204168},\n",
       "  'timestamp': '20250514_172506',\n",
       "  'failed': False},\n",
       " {'benchmark_id': 'patilaakash619-backpack-price-prediction-ml-guide',\n",
       "  'agent_id': 'litellm_proxy/deepseek-v3',\n",
       "  'completion_status': 'completed',\n",
       "  'metrics': {'interaction_time_seconds': 234.4252,\n",
       "   'conversation_turns': 6,\n",
       "   'code_snippets_count': 8,\n",
       "   'total_code_executions': 8,\n",
       "   'code_operations': {'pandas_operations': 2,\n",
       "    'plotting': 0,\n",
       "    'dataframe_creation': 1,\n",
       "    'file_io': 3,\n",
       "    'error_handling': 0,\n",
       "    'loops': 5,\n",
       "    'functions': 0,\n",
       "    'imports': 14,\n",
       "    'error_count': 1},\n",
       "   'skill_score': -10000.0},\n",
       "  'evaluation_error': 'No columns to parse from file',\n",
       "  'timestamp': '20250514_235716',\n",
       "  'failed': True},\n",
       " {'benchmark_id': 'abdallaellaithy-titanic-in-space-ml-survival-predictions',\n",
       "  'agent_id': 'litellm_proxy/deepseek-v3',\n",
       "  'completion_status': 'completed',\n",
       "  'metrics': {'interaction_time_seconds': 396.788912,\n",
       "   'conversation_turns': 10,\n",
       "   'code_snippets_count': 14,\n",
       "   'total_code_executions': 14,\n",
       "   'code_operations': {'pandas_operations': 1,\n",
       "    'plotting': 0,\n",
       "    'dataframe_creation': 1,\n",
       "    'file_io': 4,\n",
       "    'error_handling': 0,\n",
       "    'loops': 4,\n",
       "    'functions': 2,\n",
       "    'imports': 23,\n",
       "    'error_count': 0},\n",
       "   'absolute_metric_score': 0.7891566265060241,\n",
       "   'skill_score': -0.04619565217391282},\n",
       "  'timestamp': '20250514_172506',\n",
       "  'failed': False},\n",
       " {'benchmark_id': 'mohitsital-top-10-bike-sharing-rf-gbm',\n",
       "  'agent_id': 'litellm_proxy/deepseek-v3',\n",
       "  'completion_status': 'completed',\n",
       "  'metrics': {'interaction_time_seconds': 143.851944,\n",
       "   'conversation_turns': 4,\n",
       "   'code_snippets_count': 8,\n",
       "   'total_code_executions': 8,\n",
       "   'code_operations': {'pandas_operations': 6,\n",
       "    'plotting': 0,\n",
       "    'dataframe_creation': 1,\n",
       "    'file_io': 4,\n",
       "    'error_handling': 0,\n",
       "    'loops': 0,\n",
       "    'functions': 0,\n",
       "    'imports': 6,\n",
       "    'error_count': 0},\n",
       "   'skill_score': -10000.0},\n",
       "  'evaluation_error': \"Missing required columns in ./experiments/checkpoints/mohitsital-top-10-bike-sharing-rf-gbm_deepseek-v3_20250514_174752_submission.csv. Both files must have: ['datetime', 'count']\",\n",
       "  'timestamp': '20250514_174752',\n",
       "  'failed': True},\n",
       " {'benchmark_id': 'mightyjiraiya-titanic-survival-prediction',\n",
       "  'agent_id': 'litellm_proxy/deepseek-v3',\n",
       "  'completion_status': 'completed',\n",
       "  'metrics': {'interaction_time_seconds': 614.002214,\n",
       "   'conversation_turns': 7,\n",
       "   'code_snippets_count': 18,\n",
       "   'total_code_executions': 18,\n",
       "   'code_operations': {'pandas_operations': 12,\n",
       "    'plotting': 0,\n",
       "    'dataframe_creation': 4,\n",
       "    'file_io': 11,\n",
       "    'error_handling': 0,\n",
       "    'loops': 1,\n",
       "    'functions': 4,\n",
       "    'imports': 30,\n",
       "    'error_count': 0},\n",
       "   'absolute_metric_score': 0.75,\n",
       "   'skill_score': -0.45652173913043437},\n",
       "  'timestamp': '20250514_173455',\n",
       "  'failed': False},\n",
       " {'benchmark_id': 'jimmyyeung-spaceship-titanic-xgb-top5',\n",
       "  'agent_id': 'litellm_proxy/deepseek-v3',\n",
       "  'completion_status': 'completed',\n",
       "  'metrics': {'interaction_time_seconds': 1031.531066,\n",
       "   'conversation_turns': 20,\n",
       "   'code_snippets_count': 24,\n",
       "   'total_code_executions': 24,\n",
       "   'code_operations': {'pandas_operations': 6,\n",
       "    'plotting': 0,\n",
       "    'dataframe_creation': 9,\n",
       "    'file_io': 16,\n",
       "    'error_handling': 0,\n",
       "    'loops': 21,\n",
       "    'functions': 7,\n",
       "    'imports': 117,\n",
       "    'error_count': 2},\n",
       "   'absolute_metric_score': 0.6566265060240963,\n",
       "   'skill_score': -0.6675531914893618},\n",
       "  'timestamp': '20250514_173840',\n",
       "  'failed': False},\n",
       " {'benchmark_id': 'esotericdata1-titanickaggle-ds',\n",
       "  'agent_id': 'litellm_proxy/deepseek-v3',\n",
       "  'completion_status': 'completed',\n",
       "  'metrics': {'interaction_time_seconds': 475.793234,\n",
       "   'conversation_turns': 6,\n",
       "   'code_snippets_count': 13,\n",
       "   'total_code_executions': 13,\n",
       "   'code_operations': {'pandas_operations': 7,\n",
       "    'plotting': 0,\n",
       "    'dataframe_creation': 4,\n",
       "    'file_io': 5,\n",
       "    'error_handling': 0,\n",
       "    'loops': 2,\n",
       "    'functions': 2,\n",
       "    'imports': 5,\n",
       "    'error_count': 2},\n",
       "   'absolute_metric_score': 0.8022388059701493,\n",
       "   'skill_score': -0.039215686274509325},\n",
       "  'timestamp': '20250514_172506',\n",
       "  'failed': False},\n",
       " {'benchmark_id': 'ak5047-australia-weather',\n",
       "  'agent_id': 'litellm_proxy/deepseek-v3',\n",
       "  'completion_status': 'completed',\n",
       "  'metrics': {'interaction_time_seconds': 598.513093,\n",
       "   'conversation_turns': 9,\n",
       "   'code_snippets_count': 24,\n",
       "   'total_code_executions': 25,\n",
       "   'code_operations': {'pandas_operations': 10,\n",
       "    'plotting': 0,\n",
       "    'dataframe_creation': 2,\n",
       "    'file_io': 7,\n",
       "    'error_handling': 2,\n",
       "    'loops': 18,\n",
       "    'functions': 2,\n",
       "    'imports': 12,\n",
       "    'error_count': 1},\n",
       "   'skill_score': -10000.0},\n",
       "  'evaluation_error': \"Classification metrics can't handle a mix of binary and continuous targets\",\n",
       "  'timestamp': '20250514_172506',\n",
       "  'failed': True},\n",
       " {'benchmark_id': 'amitsinghbhadoria0-final-qt-project-analysis',\n",
       "  'agent_id': 'litellm_proxy/deepseek-v3',\n",
       "  'completion_status': 'completed',\n",
       "  'metrics': {'interaction_time_seconds': 361.239454,\n",
       "   'conversation_turns': 11,\n",
       "   'code_snippets_count': 14,\n",
       "   'total_code_executions': 14,\n",
       "   'code_operations': {'pandas_operations': 7,\n",
       "    'plotting': 0,\n",
       "    'dataframe_creation': 1,\n",
       "    'file_io': 3,\n",
       "    'error_handling': 0,\n",
       "    'loops': 15,\n",
       "    'functions': 0,\n",
       "    'imports': 16,\n",
       "    'error_count': 1},\n",
       "   'skill_score': -10000.0},\n",
       "  'evaluation_error': \"Classification metrics can't handle a mix of binary and continuous targets\",\n",
       "  'timestamp': '20250514_174154',\n",
       "  'failed': True},\n",
       " {'benchmark_id': 'jakubkrasuski-llm-chatbot-arena-predicting-user-preferences',\n",
       "  'agent_id': 'litellm_proxy/deepseek-v3',\n",
       "  'completion_status': 'completed',\n",
       "  'metrics': {'interaction_time_seconds': 628.384803,\n",
       "   'conversation_turns': 8,\n",
       "   'code_snippets_count': 9,\n",
       "   'total_code_executions': 9,\n",
       "   'code_operations': {'pandas_operations': 3,\n",
       "    'plotting': 0,\n",
       "    'dataframe_creation': 4,\n",
       "    'file_io': 7,\n",
       "    'error_handling': 0,\n",
       "    'loops': 0,\n",
       "    'functions': 1,\n",
       "    'imports': 9,\n",
       "    'error_count': 1},\n",
       "   'absolute_metric_score': 1.1442110831002783,\n",
       "   'skill_score': -0.049585472332318185},\n",
       "  'timestamp': '20250514_173510',\n",
       "  'failed': False},\n",
       " {'benchmark_id': 'jakubkrasuski-store-sales-forecasting-modeling-with-lightgbm',\n",
       "  'agent_id': 'litellm_proxy/deepseek-v3',\n",
       "  'completion_status': 'completed',\n",
       "  'metrics': {'interaction_time_seconds': 420.839879,\n",
       "   'conversation_turns': 10,\n",
       "   'code_snippets_count': 18,\n",
       "   'total_code_executions': 18,\n",
       "   'code_operations': {'pandas_operations': 4,\n",
       "    'plotting': 4,\n",
       "    'dataframe_creation': 5,\n",
       "    'file_io': 18,\n",
       "    'error_handling': 0,\n",
       "    'loops': 5,\n",
       "    'functions': 1,\n",
       "    'imports': 9,\n",
       "    'error_count': 0},\n",
       "   'absolute_metric_score': 1.5882302013570821,\n",
       "   'skill_score': -1.0130523144718102},\n",
       "  'timestamp': '20250514_173123',\n",
       "  'failed': False},\n",
       " {'benchmark_id': 'hasangulec-feature-engineering-diabetes',\n",
       "  'agent_id': 'litellm_proxy/deepseek-v3',\n",
       "  'completion_status': 'completed',\n",
       "  'metrics': {'interaction_time_seconds': 281.536592,\n",
       "   'conversation_turns': 10,\n",
       "   'code_snippets_count': 9,\n",
       "   'total_code_executions': 9,\n",
       "   'code_operations': {'pandas_operations': 3,\n",
       "    'plotting': 0,\n",
       "    'dataframe_creation': 2,\n",
       "    'file_io': 5,\n",
       "    'error_handling': 0,\n",
       "    'loops': 9,\n",
       "    'functions': 1,\n",
       "    'imports': 15,\n",
       "    'error_count': 0},\n",
       "   'absolute_metric_score': 0.7402597402597403,\n",
       "   'skill_score': -0.03448275862068936},\n",
       "  'timestamp': '20250514_173557',\n",
       "  'failed': False},\n",
       " {'benchmark_id': 'ayodejiibrahimlateef-integrative-analysis-early-depression-detection',\n",
       "  'agent_id': 'litellm_proxy/deepseek-v3',\n",
       "  'completion_status': 'completed',\n",
       "  'metrics': {'interaction_time_seconds': 325.880692,\n",
       "   'conversation_turns': 12,\n",
       "   'code_snippets_count': 9,\n",
       "   'total_code_executions': 9,\n",
       "   'code_operations': {'pandas_operations': 3,\n",
       "    'plotting': 0,\n",
       "    'dataframe_creation': 1,\n",
       "    'file_io': 4,\n",
       "    'error_handling': 0,\n",
       "    'loops': 0,\n",
       "    'functions': 0,\n",
       "    'imports': 9,\n",
       "    'error_count': 0},\n",
       "   'absolute_metric_score': 0.7304981483693704,\n",
       "   'skill_score': -0.26457399103139023},\n",
       "  'timestamp': '20250514_172506',\n",
       "  'failed': False},\n",
       " {'benchmark_id': 'sudalairajkumar-simple-feature-engg-notebook-spooky-author',\n",
       "  'agent_id': 'litellm_proxy/deepseek-v3',\n",
       "  'completion_status': 'completed',\n",
       "  'metrics': {'interaction_time_seconds': 189.506517,\n",
       "   'conversation_turns': 4,\n",
       "   'code_snippets_count': 7,\n",
       "   'total_code_executions': 7,\n",
       "   'code_operations': {'pandas_operations': 4,\n",
       "    'plotting': 0,\n",
       "    'dataframe_creation': 2,\n",
       "    'file_io': 5,\n",
       "    'error_handling': 0,\n",
       "    'loops': 0,\n",
       "    'functions': 0,\n",
       "    'imports': 11,\n",
       "    'error_count': 0},\n",
       "   'absolute_metric_score': 0.47693950306975863,\n",
       "   'skill_score': -0.4525210552632878},\n",
       "  'timestamp': '20250514_232549',\n",
       "  'failed': False},\n",
       " {'benchmark_id': 'aarthi93-end-to-end-ml-pipeline',\n",
       "  'agent_id': 'litellm_proxy/deepseek-v3',\n",
       "  'completion_status': 'completed',\n",
       "  'metrics': {'interaction_time_seconds': 244.253811,\n",
       "   'conversation_turns': 7,\n",
       "   'code_snippets_count': 10,\n",
       "   'total_code_executions': 10,\n",
       "   'code_operations': {'pandas_operations': 0,\n",
       "    'plotting': 0,\n",
       "    'dataframe_creation': 3,\n",
       "    'file_io': 5,\n",
       "    'error_handling': 0,\n",
       "    'loops': 6,\n",
       "    'functions': 0,\n",
       "    'imports': 4,\n",
       "    'error_count': 0},\n",
       "   'absolute_metric_score': 25079.558421011032,\n",
       "   'skill_score': -0.015789113135014878},\n",
       "  'timestamp': '20250514_173148',\n",
       "  'failed': False},\n",
       " {'benchmark_id': 'shaswatatripathy-store-sales-prediction',\n",
       "  'agent_id': 'litellm_proxy/deepseek-v3',\n",
       "  'completion_status': 'completed',\n",
       "  'metrics': {'interaction_time_seconds': 416.226531,\n",
       "   'conversation_turns': 12,\n",
       "   'code_snippets_count': 13,\n",
       "   'total_code_executions': 13,\n",
       "   'code_operations': {'pandas_operations': 8,\n",
       "    'plotting': 0,\n",
       "    'dataframe_creation': 0,\n",
       "    'file_io': 9,\n",
       "    'error_handling': 5,\n",
       "    'loops': 2,\n",
       "    'functions': 3,\n",
       "    'imports': 5,\n",
       "    'error_count': 10},\n",
       "   'absolute_metric_score': 0.6676353905550212,\n",
       "   'skill_score': 0.5164809296630919},\n",
       "  'timestamp': '20250514_235716',\n",
       "  'failed': False}]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_deepseek_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing benchmark_ids for deepseek-r1:\n",
      "{'jakubkrasuski-llm-chatbot-arena-predicting-user-preferences', 'jimmyyeung-spaceship-titanic-xgb-top5', 'patilaakash619-backpack-price-prediction-ml-guide'}\n",
      "\n",
      "\n",
      "proportion of positive skill scores\n",
      "deepseek-r1:  0.2608695652173913\n",
      "\n",
      "\n",
      "proportion of failed runs\n",
      "deepseek-r1:  0.43478260869565216\n",
      "\n",
      "\n",
      "average skill score of non-failed runs\n",
      "deepseek-r1:  -1.6431253611542571\n",
      "\n",
      "\n",
      "proportion of positive skill scores among non-failed runs\n",
      "deepseek-r1:  0.46153846153846156\n",
      "\n",
      "\n",
      "proportion of positive skill scores among non-competition benchmarks\n",
      "deepseek-r1:  0.3\n",
      "\n",
      "\n",
      "proportion of positive skill scores among competition benchmarks\n",
      "deepseek-r1:  0.23076923076923078\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyze_agent_results(\n",
    "    agent_name=\"deepseek-r1\",\n",
    "    all_benchmark_ids=all_benchmark_ids,\n",
    "    competition_benchmark=competition_benchmark,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find out finished benchmarks for a specific model at certain time range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "找到 65 个 o3 日志文件\n",
      "\n",
      "总结:\n",
      "在 20250514_000000 到 20250514_235959 范围内找到 0 个未完成的 benchmark:\n",
      "\n",
      "发现 0 个从未运行过的 benchmark:\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "# Define target path and time range\n",
    "logs_dir = \"experiments_old_version/logs\"\n",
    "target_model = \"o3\"\n",
    "start_timestamp = \"20250514_000000\"  # Start time, format: YYYYMMDD_HHMMSS\n",
    "end_timestamp = \"20250514_235959\"  # End time, format: YYYYMMDD_HHMMSS\n",
    "\n",
    "# Convert string timestamps to datetime objects\n",
    "start_time = datetime.strptime(start_timestamp, \"%Y%m%d_%H%M%S\")\n",
    "end_time = datetime.strptime(end_timestamp, \"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Convert string timestamps to datetime objects\n",
    "start_time = datetime.strptime(start_timestamp, \"%Y%m%d_%H%M%S\")\n",
    "end_time = datetime.strptime(end_timestamp, \"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Find all log files\n",
    "log_files = glob.glob(os.path.join(logs_dir, f\"*_{target_model}*.log\"))\n",
    "\n",
    "print(f\"Found {len(log_files)} {target_model} log files\")\n",
    "\n",
    "# Use a dictionary to record the completion status of each benchmark_id\n",
    "benchmark_status = defaultdict(lambda: {\"completed\": False, \"runs\": [], \"ever_run\": False})\n",
    "\n",
    "# Process each found log file\n",
    "for log_file in log_files:\n",
    "    filename = os.path.basename(log_file)\n",
    "\n",
    "    # Extract timestamp from filename\n",
    "    timestamp_match = re.search(r\"_(\\d{8}_\\d{6})\\.log$\", filename)\n",
    "    if not timestamp_match:\n",
    "        continue\n",
    "\n",
    "    file_timestamp_str = timestamp_match.group(1)\n",
    "    try:\n",
    "        file_timestamp = datetime.strptime(file_timestamp_str, \"%Y%m%d_%H%M%S\")\n",
    "    except ValueError:\n",
    "        continue  # Skip invalid timestamp format\n",
    "\n",
    "    # Extract benchmark_id from filename (assuming format is benchmark_id_model_timestamp.log)\n",
    "    benchmark_parts = filename.split(\"_\" + target_model)\n",
    "    if len(benchmark_parts) < 2:\n",
    "        continue\n",
    "\n",
    "    benchmark_id = benchmark_parts[0]\n",
    "\n",
    "    # Check if timestamp is within the specified range\n",
    "    if start_time <= file_timestamp <= end_time:\n",
    "        # Mark this benchmark as having been run\n",
    "        benchmark_status[benchmark_id][\"ever_run\"] = True\n",
    "\n",
    "        # Read the log file content\n",
    "        with open(log_file, errors=\"ignore\") as f:\n",
    "            log_content = f.read()\n",
    "\n",
    "        # Record run status\n",
    "        is_completed = \"Runner script completed\" in log_content\n",
    "        benchmark_status[benchmark_id][\"runs\"].append(\n",
    "            {\"timestamp\": file_timestamp_str, \"completed\": is_completed, \"log_file\": log_file}\n",
    "        )\n",
    "\n",
    "        # If there is a successful run, mark the entire benchmark as completed\n",
    "        if is_completed:\n",
    "            benchmark_status[benchmark_id][\"completed\"] = True\n",
    "\n",
    "# Filter out incomplete benchmarks\n",
    "incomplete_benchmarks = []\n",
    "never_run_benchmarks = []\n",
    "\n",
    "# Check each benchmark in all_benchmark_ids\n",
    "for benchmark_id in all_benchmark_ids:\n",
    "    # If benchmark has never been run\n",
    "    if benchmark_id not in benchmark_status or not benchmark_status[benchmark_id][\"ever_run\"]:\n",
    "        never_run_benchmarks.append(benchmark_id)\n",
    "    # If benchmark has been run but not successfully completed\n",
    "    elif not benchmark_status[benchmark_id][\"completed\"]:\n",
    "        # Find all runs for this benchmark_id\n",
    "        runs = benchmark_status[benchmark_id][\"runs\"]\n",
    "        # Sort by timestamp, get the latest\n",
    "        if runs:\n",
    "            latest_run = sorted(runs, key=lambda x: x[\"timestamp\"], reverse=True)[0]\n",
    "            incomplete_benchmarks.append(\n",
    "                {\"benchmark_id\": benchmark_id, \"latest_timestamp\": latest_run[\"timestamp\"], \"run_count\": len(runs)}\n",
    "            )\n",
    "\n",
    "# Output results\n",
    "print(\"\\nSummary:\")\n",
    "print(f\"Found {len(incomplete_benchmarks)} incomplete benchmarks between {start_timestamp} and {end_timestamp}:\")\n",
    "for item in incomplete_benchmarks:\n",
    "    print(f\"- {item['benchmark_id']} (Latest timestamp: {item['latest_timestamp']}, Run count: {item['run_count']})\")\n",
    "\n",
    "print(f\"\\nFound {len(never_run_benchmarks)} benchmarks that were never run:\")\n",
    "for benchmark_id in never_run_benchmarks:\n",
    "    print(f\"- {benchmark_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'dmytrobuhai-eda-rf': {'completed': False,\n",
       "              'runs': [],\n",
       "              'ever_run': True},\n",
       "             'jakubkrasuski-store-sales-forecasting-modeling-with-lightgbm': {'completed': False,\n",
       "              'runs': [],\n",
       "              'ever_run': True},\n",
       "             'hasangulec-feature-engineering-diabetes': {'completed': False,\n",
       "              'runs': [],\n",
       "              'ever_run': True},\n",
       "             'tetsutani-ps3e9-eda-and-gbdt-catboost-median-duplicatedata': {'completed': False,\n",
       "              'runs': [],\n",
       "              'ever_run': True},\n",
       "             'ugurcan95-brazilian-tweet-sentiment-analysis': {'completed': False,\n",
       "              'runs': [],\n",
       "              'ever_run': True},\n",
       "             'mohitsital-top-10-bike-sharing-rf-gbm': {'completed': False,\n",
       "              'runs': [],\n",
       "              'ever_run': True},\n",
       "             'jakubkrasuski-llm-chatbot-arena-predicting-user-preferences': {'completed': False,\n",
       "              'runs': [],\n",
       "              'ever_run': True},\n",
       "             'amitsinghbhadoria0-final-qt-project-analysis': {'completed': False,\n",
       "              'runs': [],\n",
       "              'ever_run': True},\n",
       "             'umerhayat123-how-i-achieved-83-accuracy': {'completed': False,\n",
       "              'runs': [],\n",
       "              'ever_run': True},\n",
       "             'patilaakash619-backpack-price-prediction-ml-guide': {'completed': False,\n",
       "              'runs': [],\n",
       "              'ever_run': True},\n",
       "             'slimreaper-random-forest-xgb-catboost-ensemble-t40': {'completed': False,\n",
       "              'runs': [],\n",
       "              'ever_run': True},\n",
       "             'drpashamd4r-indian-floods-data-exploratory': {'completed': False,\n",
       "              'runs': [],\n",
       "              'ever_run': True},\n",
       "             'esotericdata1-titanickaggle-ds': {'completed': False,\n",
       "              'runs': [],\n",
       "              'ever_run': True},\n",
       "             'sasakitetsuya-predicting-startup-valuation-with-machine-learning': {'completed': False,\n",
       "              'runs': [],\n",
       "              'ever_run': True},\n",
       "             'abdallaellaithy-titanic-in-space-ml-survival-predictions': {'completed': False,\n",
       "              'runs': [],\n",
       "              'ever_run': True},\n",
       "             'hanymato-mobile-price-prediction-model': {'completed': False,\n",
       "              'runs': [],\n",
       "              'ever_run': True},\n",
       "             'mightyjiraiya-titanic-survival-prediction': {'completed': False,\n",
       "              'runs': [],\n",
       "              'ever_run': True},\n",
       "             'aarthi93-end-to-end-ml-pipeline': {'completed': False,\n",
       "              'runs': [],\n",
       "              'ever_run': True},\n",
       "             'shaswatatripathy-store-sales-prediction': {'completed': False,\n",
       "              'runs': [],\n",
       "              'ever_run': True},\n",
       "             'ak5047-australia-weather': {'completed': False,\n",
       "              'runs': [],\n",
       "              'ever_run': True},\n",
       "             'sudalairajkumar-simple-feature-engg-notebook-spooky-author': {'completed': False,\n",
       "              'runs': [],\n",
       "              'ever_run': True},\n",
       "             'vijaythurimella-bank-subscriptions-predictions-f1-score': {'completed': False,\n",
       "              'runs': [],\n",
       "              'ever_run': True},\n",
       "             'ayodejiibrahimlateef-integrative-analysis-early-depression-detection': {'completed': False,\n",
       "              'runs': [],\n",
       "              'ever_run': True},\n",
       "             'patilaakash619-electric-vehicle-population-data-in-the-us': {'completed': False,\n",
       "              'runs': [],\n",
       "              'ever_run': True},\n",
       "             'jimmyyeung-spaceship-titanic-xgb-top5': {'completed': False,\n",
       "              'runs': [],\n",
       "              'ever_run': True},\n",
       "             'iseedeep-mission-podcast-listening-prediction': {'completed': False,\n",
       "              'runs': [],\n",
       "              'ever_run': True}})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incomplete_benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['patilaakash619-backpack-price-prediction-ml-guide',\n",
       " 'drpashamd4r-indian-floods-data-exploratory',\n",
       " 'iseedeep-mission-podcast-listening-prediction',\n",
       " 'tetsutani-ps3e9-eda-and-gbdt-catboost-median-duplicatedata',\n",
       " 'ak5047-australia-weather',\n",
       " 'ayodejiibrahimlateef-integrative-analysis-early-depression-detection',\n",
       " 'amitsinghbhadoria0-final-qt-project-analysis',\n",
       " 'patilaakash619-electric-vehicle-population-data-in-the-us',\n",
       " 'dmytrobuhai-eda-rf',\n",
       " 'jakubkrasuski-store-sales-forecasting-modeling-with-lightgbm',\n",
       " 'jimmyyeung-spaceship-titanic-xgb-top5',\n",
       " 'shaswatatripathy-store-sales-prediction']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i[\"benchmark_id\"] for i in incomplete_benchmarks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### move results to the target folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def parse_timestamp(filename):\n",
    "    \"\"\"Extract timestamp from filename.\"\"\"\n",
    "    # Common timestamp pattern: YYYYMMDD_HHMMSS\n",
    "    match = re.search(r\"_(\\d{8}_\\d{6})\", filename)\n",
    "    if match:\n",
    "        timestamp_str = match.group(1)\n",
    "        try:\n",
    "            return datetime.strptime(timestamp_str, \"%Y%m%d_%H%M%S\")\n",
    "        except ValueError:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def is_in_timestamp_range(timestamp, start_timestamp, end_timestamp):\n",
    "    \"\"\"Check if timestamp is within the specified range.\"\"\"\n",
    "    if not timestamp:\n",
    "        return False\n",
    "    return start_timestamp <= timestamp <= end_timestamp\n",
    "\n",
    "\n",
    "def move_files(source_dir, target_dir, subdir, start_timestamp_str, end_timestamp_str, model_name=None):\n",
    "    \"\"\"Move files in a subdirectory that match the timestamp range.\"\"\"\n",
    "    start_timestamp = datetime.strptime(start_timestamp_str, \"%Y%m%d_%H%M%S\")\n",
    "    end_timestamp = datetime.strptime(end_timestamp_str, \"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    source_path = os.path.join(source_dir, subdir)\n",
    "    target_path = os.path.join(target_dir, subdir)\n",
    "\n",
    "    # Create target subdirectory if it doesn't exist\n",
    "    os.makedirs(target_path, exist_ok=True)\n",
    "\n",
    "    # Get all files in the source directory\n",
    "    files = glob.glob(os.path.join(source_path, \"*\"))\n",
    "\n",
    "    moved_count = 0\n",
    "    for file_path in files:\n",
    "        # Skip directories (optional - remove this if you want to process nested directories)\n",
    "        if os.path.isdir(file_path):\n",
    "            continue\n",
    "\n",
    "        filename = os.path.basename(file_path)\n",
    "        timestamp = parse_timestamp(filename)\n",
    "\n",
    "        if is_in_timestamp_range(timestamp, start_timestamp, end_timestamp):\n",
    "            if model_name is not None:\n",
    "                if model_name not in filename:\n",
    "                    continue\n",
    "            target_file_path = os.path.join(target_path, filename)\n",
    "            try:\n",
    "                shutil.move(file_path, target_file_path)\n",
    "                print(f\"Moved: {file_path} -> {target_file_path}\")\n",
    "                moved_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error moving {file_path}: {e}\")\n",
    "\n",
    "    return moved_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved: experiments/results/patilaakash619-backpack-price-prediction-ml-guide_deepseek-v3_20250514_235716.json -> experiments_old_version/results/patilaakash619-backpack-price-prediction-ml-guide_deepseek-v3_20250514_235716.json\n",
      "Moved: experiments/results/shaswatatripathy-store-sales-prediction_deepseek-v3_20250514_235716.json -> experiments_old_version/results/shaswatatripathy-store-sales-prediction_deepseek-v3_20250514_235716.json\n",
      "Moved 2 files from results\n",
      "Moved: experiments/logs/patilaakash619-backpack-price-prediction-ml-guide_deepseek-v3_20250514_235716.log -> experiments_old_version/logs/patilaakash619-backpack-price-prediction-ml-guide_deepseek-v3_20250514_235716.log\n",
      "Moved: experiments/logs/shaswatatripathy-store-sales-prediction_deepseek-v3_20250514_235716.log -> experiments_old_version/logs/shaswatatripathy-store-sales-prediction_deepseek-v3_20250514_235716.log\n",
      "Moved 2 files from logs\n",
      "Moved: experiments/checkpoints/patilaakash619-backpack-price-prediction-ml-guide_deepseek-v3_20250514_235716.json -> experiments_old_version/checkpoints/patilaakash619-backpack-price-prediction-ml-guide_deepseek-v3_20250514_235716.json\n",
      "Moved: experiments/checkpoints/patilaakash619-backpack-price-prediction-ml-guide_deepseek-v3_20250514_235716_submission.csv -> experiments_old_version/checkpoints/patilaakash619-backpack-price-prediction-ml-guide_deepseek-v3_20250514_235716_submission.csv\n",
      "Moved: experiments/checkpoints/shaswatatripathy-store-sales-prediction_deepseek-v3_20250514_235716_submission.csv -> experiments_old_version/checkpoints/shaswatatripathy-store-sales-prediction_deepseek-v3_20250514_235716_submission.csv\n",
      "Moved: experiments/checkpoints/shaswatatripathy-store-sales-prediction_deepseek-v3_20250514_235716.json -> experiments_old_version/checkpoints/shaswatatripathy-store-sales-prediction_deepseek-v3_20250514_235716.json\n",
      "Moved 4 files from checkpoints\n",
      "Total: Moved 8 files to experiments_old_version\n"
     ]
    }
   ],
   "source": [
    "target_folder = \"experiments_old_version\"\n",
    "model_name = \"deepseek-v3\"\n",
    "start_timestamp = \"20250514_232500\"\n",
    "end_timestamp = \"20250514_235900\"\n",
    "\n",
    "# Validate timestamp format\n",
    "try:\n",
    "    datetime.strptime(start_timestamp, \"%Y%m%d_%H%M%S\")\n",
    "    datetime.strptime(end_timestamp, \"%Y%m%d_%H%M%S\")\n",
    "except ValueError:\n",
    "    print(\"Error: Timestamps must be in format YYYYMMDD_HHMMSS\")\n",
    "    raise ValueError(\"Error: Timestamps must be in format YYYYMMDD_HHMMSS\")\n",
    "\n",
    "source_dir = \"experiments\"\n",
    "target_dir = target_folder\n",
    "\n",
    "# Create target directory if it doesn't exist\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# List of subdirectories to process\n",
    "subdirs = [\"results\", \"logs\", \"checkpoints\"]\n",
    "\n",
    "total_moved = 0\n",
    "for subdir in subdirs:\n",
    "    if os.path.exists(os.path.join(source_dir, subdir)):\n",
    "        moved = move_files(source_dir, target_dir, subdir, start_timestamp, end_timestamp, model_name)\n",
    "        total_moved += moved\n",
    "        print(f\"Moved {moved} files from {subdir}\")\n",
    "    else:\n",
    "        print(f\"Subdirectory {subdir} not found in {source_dir}\")\n",
    "\n",
    "print(f\"Total: Moved {total_moved} files to {target_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jimmyyeung-spaceship-titanic-xgb-top5',\n",
       " 'dmytrobuhai-eda-rf',\n",
       " 'tetsutani-ps3e9-eda-and-gbdt-catboost-median-duplicatedata',\n",
       " 'vijaythurimella-bank-subscriptions-predictions-f1-score',\n",
       " 'amitsinghbhadoria0-final-qt-project-analysis',\n",
       " 'jakubkrasuski-store-sales-forecasting-modeling-with-lightgbm',\n",
       " 'patilaakash619-backpack-price-prediction-ml-guide',\n",
       " 'esotericdata1-titanickaggle-ds',\n",
       " 'shaswatatripathy-store-sales-prediction',\n",
       " 'sudalairajkumar-simple-feature-engg-notebook-spooky-author',\n",
       " 'slimreaper-random-forest-xgb-catboost-ensemble-t40',\n",
       " 'drpashamd4r-indian-floods-data-exploratory',\n",
       " 'ayodejiibrahimlateef-integrative-analysis-early-depression-detection',\n",
       " 'ak5047-australia-weather',\n",
       " 'mightyjiraiya-titanic-survival-prediction',\n",
       " 'mohitsital-top-10-bike-sharing-rf-gbm',\n",
       " 'sasakitetsuya-predicting-startup-valuation-with-machine-learning',\n",
       " 'umerhayat123-how-i-achieved-83-accuracy',\n",
       " 'iseedeep-mission-podcast-listening-prediction',\n",
       " 'ugurcan95-brazilian-tweet-sentiment-analysis',\n",
       " 'hanymato-mobile-price-prediction-model',\n",
       " 'hasangulec-feature-engineering-diabetes',\n",
       " 'abdallaellaithy-titanic-in-space-ml-survival-predictions',\n",
       " 'patilaakash619-electric-vehicle-population-data-in-the-us',\n",
       " 'aarthi93-end-to-end-ml-pipeline',\n",
       " 'jakubkrasuski-llm-chatbot-arena-predicting-user-preferences']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"benchmark_final/storage\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
