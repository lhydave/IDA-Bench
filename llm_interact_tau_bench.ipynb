{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any, Optional\n",
    "from copy import deepcopy\n",
    "\n",
    "from llm_interact import LLMInteractor, LLMConfig\n",
    "from llm_interact_env import Environment, EnvironmentConfig, Task, run\n",
    "from logger import logger  # Import the logger\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This just follows tau-bench, where we provide a paragraph of instruction and task, then let the user llm and agent llm talk with each other without our intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 23:19:37 - DataSciBench - INFO - Loaded configuration from ./llm_config_user.toml\n",
      "2025-04-30 23:19:37 - DataSciBench - INFO - Loaded configuration from ./llm_config_agent.toml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 23:19:37 - DataSciBench - INFO - Initializing Environment with 1 tasks\n",
      "2025-04-30 23:19:37 - DataSciBench - INFO - Initialized LLMInteractor with model: gemini/gemini-2.5-flash-preview-04-17, temperature: 0.4\n",
      "2025-04-30 23:19:37 - DataSciBench - INFO - Initialized LLMInteractor with model: gemini/gemini-2.5-flash-preview-04-17, temperature: 0.4\n",
      "2025-04-30 23:19:37 - DataSciBench - INFO - Starting environment run with version: taubench\n",
      "2025-04-30 23:19:37 - DataSciBench - INFO - Starting interaction between agents\n",
      "2025-04-30 23:19:37 - DataSciBench - INFO - Starting interaction using version2 strategy\n",
      "2025-04-30 23:19:37 - DataSciBench - INFO - Starting task loop with max turns: 30\n",
      "2025-04-30 23:19:37 - DataSciBench - INFO - Calling LLM API with a message (total length: ~59 chars)\n",
      "2025-04-30 23:19:38 - DataSciBench - INFO - LLM API call successful on attempt 1\n",
      "2025-04-30 23:19:38 - DataSciBench - INFO - Checkpoint saved successfully\n",
      "2025-04-30 23:19:38 - DataSciBench - INFO - Calling LLM API with a message (total length: ~150 chars)\n",
      "2025-04-30 23:19:40 - DataSciBench - INFO - LLM API call successful on attempt 1\n",
      "2025-04-30 23:19:40 - DataSciBench - INFO - Checkpoint saved successfully\n",
      "2025-04-30 23:19:40 - DataSciBench - INFO - Turn 1 completed\n",
      "2025-04-30 23:19:40 - DataSciBench - INFO - Calling LLM API with a message (total length: ~390 chars)\n",
      "2025-04-30 23:19:41 - DataSciBench - INFO - LLM API call successful on attempt 1\n",
      "2025-04-30 23:19:41 - DataSciBench - INFO - Checkpoint saved successfully\n",
      "2025-04-30 23:19:41 - DataSciBench - INFO - Calling LLM API with a message (total length: ~128 chars)\n",
      "2025-04-30 23:19:43 - DataSciBench - INFO - LLM API call successful on attempt 1\n",
      "2025-04-30 23:19:43 - DataSciBench - INFO - Checkpoint saved successfully\n",
      "2025-04-30 23:19:43 - DataSciBench - INFO - Turn 2 completed\n",
      "2025-04-30 23:19:43 - DataSciBench - INFO - Calling LLM API with a message (total length: ~387 chars)\n",
      "2025-04-30 23:19:44 - DataSciBench - INFO - LLM API call successful on attempt 1\n",
      "2025-04-30 23:19:44 - DataSciBench - INFO - Checkpoint saved successfully\n",
      "2025-04-30 23:19:44 - DataSciBench - INFO - Calling LLM API with a message (total length: ~98 chars)\n",
      "2025-04-30 23:19:46 - DataSciBench - INFO - LLM API call successful on attempt 1\n",
      "2025-04-30 23:19:46 - DataSciBench - INFO - Checkpoint saved successfully\n",
      "2025-04-30 23:19:46 - DataSciBench - INFO - Turn 3 completed\n",
      "2025-04-30 23:19:46 - DataSciBench - INFO - Calling LLM API with a message (total length: ~0 chars)\n",
      "2025-04-30 23:19:46 - DataSciBench - INFO - LLM API call successful on attempt 1\n",
      "2025-04-30 23:19:46 - DataSciBench - WARNING - LLM API call failed (attempt 1/3): list index out of range\n",
      "2025-04-30 23:19:46 - DataSciBench - INFO - Retrying in 2 seconds...\n",
      "2025-04-30 23:19:49 - DataSciBench - INFO - LLM API call successful on attempt 2\n",
      "2025-04-30 23:19:49 - DataSciBench - WARNING - LLM API call failed (attempt 2/3): list index out of range\n",
      "2025-04-30 23:19:49 - DataSciBench - INFO - Retrying in 4 seconds...\n",
      "2025-04-30 23:19:54 - DataSciBench - INFO - LLM API call successful on attempt 3\n",
      "2025-04-30 23:19:54 - DataSciBench - WARNING - LLM API call failed (attempt 3/3): list index out of range\n",
      "2025-04-30 23:19:54 - DataSciBench - ERROR - All 3 attempts to call LLM API failed. Last error: list index out of range\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Create and run the environment\u001b[39;00m\n\u001b[32m     44\u001b[39m environment = Environment(env_config, tasks)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m completed_tasks = \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtaubench\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataSciBench/llm_interact_env.py:486\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(env, version_name)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:21\u001b[39m, in \u001b[36minteract_version_taubench\u001b[39m\u001b[34m(env, user_agent, assistant_agent)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataSciBench/llm_interact.py:204\u001b[39m, in \u001b[36mcall_llm\u001b[39m\u001b[34m(self, message, retry)\u001b[39m\n\u001b[32m    201\u001b[39m             time.sleep(backoff_time)\n\u001b[32m    203\u001b[39m \u001b[38;5;66;03m# If we get here, all attempts failed\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m logger.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAll \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_attempts\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m attempts to call LLM API failed. Last error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(last_exception)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m last_exception \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAll attempts to call LLM API failed\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataSciBench/llm_interact.py:187\u001b[39m, in \u001b[36mcall_llm\u001b[39m\u001b[34m(self, message, retry)\u001b[39m\n\u001b[32m    180\u001b[39m response = completion(\n\u001b[32m    181\u001b[39m     model=self.config.model,\n\u001b[32m    182\u001b[39m     temperature=self.config.temperature,\n\u001b[32m    183\u001b[39m     messages=messages,\n\u001b[32m    184\u001b[39m )\n\u001b[32m    185\u001b[39m logger.info(f\"LLM API call successful on attempt {attempt + 1}\")\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m # Add the response to the conversation history\n\u001b[32m    188\u001b[39m response_content = response.choices[0].message[\"content\"]  # type: ignore\n\u001b[32m    189\u001b[39m response_messages = {\"role\": \"assistant\", \"content\": response_content}\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define configuration for both agents\n",
    "user_config = LLMConfig.from_toml(\"./llm_config_user.toml\")\n",
    "\n",
    "assistant_config = LLMConfig.from_toml(\"./llm_config_agent.toml\")\n",
    "assistant_config.run_code = True\n",
    "\n",
    "# Define environment configuration\n",
    "env_config = EnvironmentConfig(\n",
    "    user_llm_config=user_config,\n",
    "    assistant_llm_config=assistant_config,\n",
    "    assistant_agent_type=\"base-agent\",\n",
    "    interpreter_config_path=\"interpreter_config.toml\",\n",
    "    user_prompt_template=\"\"\"\n",
    "    You are a data analyst for Walmart.\n",
    "    \n",
    "    {task_specific_instruction}\n",
    "    \"\"\",\n",
    "    max_turns=30,\n",
    "    checkpoint_path=\"trajactory_walmart.json\"\n",
    ")\n",
    "\n",
    "# Define tasks\n",
    "tasks = [\n",
    "    Task(\n",
    "        id=\"1\", \n",
    "        description=\n",
    "        \"\"\"**background**:\n",
    "        Walmart is a renowned retail corporation that operates a chain of hypermarkets. Here, Walmart has provided a data combining of 45 stores including store information and monthly sales. The data is provided on weekly basis. You received the data walmart_data/walmart.csv and your Main Objective is to predict sales of store in a week. You just joined Walmart and you are excited to start your first project.\n",
    "        \n",
    "        \n",
    "        **knowledge**:\n",
    "        \n",
    "        Missing values should be impute with zero; \n",
    "        Negative sales should be dropped; \n",
    "        The holidays might have a significant impact on sales;\n",
    "        The four holidays are Super Bowl, Labor Day, Thanksgiving, and Christmas; \n",
    "        The Holt-Winters exponential smoothing model is the best model for this task;\n",
    "        Make the data more stationary by computing a differenced series and resampling the data to weekly frequency by averaging values;\n",
    "        Calculate the weighted mean absolute error of the model, the weight on the holiday weeks should be 5, and the weight on the non-holiday weeks should be 1.\"\"\",\n",
    "        success_criteria=\"\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Create and run the environment\n",
    "environment = Environment(env_config, tasks)\n",
    "completed_tasks = run(environment, \"taubench\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
